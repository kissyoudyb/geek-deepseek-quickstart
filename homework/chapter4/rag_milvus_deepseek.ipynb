{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7394c701",
   "metadata": {},
   "source": [
    "## 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89103a1e",
   "metadata": {},
   "source": [
    "### 依赖与环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c18d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting pymilvus==2.5.10 (from pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/b0/4b/847704930ad8ddd0d0975e9a3a5e3fe704f642debe97454135c2b9ee7081/pymilvus-2.5.10-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: openai==1.82.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (1.82.0)\n",
      "Collecting requests==2.32.3\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Collecting torch==2.7.0\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/4b/27/285a8cf12bd7cd71f9f211a968516b07dcffed3ef0be585c6e823675ab91/torch-2.7.0-cp313-cp313-manylinux_2_28_x86_64.whl (865.0 MB)\n",
      "Requirement already satisfied: setuptools>69 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (78.1.1)\n",
      "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/76/9a/d21236297111052dcb5dc85cd77dc7bf25ba67a0f55ae028b2af19a704bc/grpcio-1.67.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Collecting protobuf>=3.20.0 (from pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/40/01/2e730bd1c25392fc32e3268e02446f0d77cb51a2c3a8486b1798e34d5805/protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pymilvus==2.5.10->pymilvus[model]==2.5.10) (1.1.0)\n",
      "Collecting ujson>=2.0.0 (from pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/fe/a3/292551f936d3d02d9af148f53e1bc04306b00a7cf1fcbb86fa0d1c887242/ujson-5.11.0-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
      "Collecting pandas>=1.2.4 (from pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/8f/52/0634adaace9be2d8cac9ef78f05c47f3a675882e068438b9d7ec7ef0c13f/pandas-2.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Collecting milvus-lite>=2.4.0 (from pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/d3/82/41d9b80f09b82e066894d9b508af07b7b0fa325ce0322980674de49106a0/milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from openai==1.82.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from requests==2.32.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from requests==2.32.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from requests==2.32.3) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from requests==2.32.3) (2025.8.3)\n",
      "Collecting filelock (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/42/14/42b2651a2f46b022ccd948bca9f2d5af0fd8929c4eec235b8d6d844fbe67/filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting networkx (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/eb/8d/776adee7bbf76365fdd7f2552710282c79a4ead5d2a46408c9043a2b70ba/networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from torch==2.7.0) (3.1.6)\n",
      "Collecting fsspec (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/2f/e0/014d5d9d7a4564cf1c40b5039bc882db69fd881111e03ab3657ac0b218e2/fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/75/2e/46030320b5a80661e88039f59060d1790298b4718944a65a7f2aeda3d9e9/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/e1/23/e717c5ac26d26cf39a27fbc076240fad2e3b817e5889d671b67f4f9f49c5/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/49/60/7b6497946d74bcf1de852a21824d63baad12cd417db4195fc1bfe59db953/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/2a/78/4535c9c7f859a64781e43c969a3a7e84c54634e319a996d43ef32ce46f83/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/af/eb/ff4b8c503fa1f1796679dce648854d58751982426e4e4b37d6fce49d259c/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/8f/16/73727675941ab8e6ffd86ca3a4b7b47065edcca7a997920b831f8147c99d/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/73/1b/44a01c4e70933637c93e6e1a8063d1e998b50213a6b65ac5a9169c47e98e/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/f0/6e/c2cf12c9ff8b872e92b4a5740701e51ff17689c4d726fca91875b07f655d/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/06/1e/b8b7c2f4099a37b96af5c9bb158632ea9e5d9d27d7391d7eb8fc45236674/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/3b/9a/72ef35b399b0e183bc2e8f6f558036922d453c4d8237dab26c666a04244b/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/67/ca/f42388aed0fddd64ade7493dbba36e1f534d4e6fdbdd355c6a90030ae028/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/56/9a/fff8376f8e3d084cd1530e1ef7b879bb7d6d265620c95c1b322725c694f4/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/9d/d7/c5383e47c7e9bf1c99d5bd2a8c935af2b6d705ad831a7ec5c97db4d82f4f/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/b2/66/cc9876340ac68ae71b15c743ddb13f8b30d5244af344ec8322b449e35426/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Collecting triton==3.3.0 (from torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/7d/74/4bf2702b65e93accaa20397b74da46fb7a0356452c1bb94dbabaf0582930/triton-3.3.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "Collecting pymilvus.model>=0.3.0 (from pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/5b/ba/b34e3f8c57c453c02daf1a1eff9c4b62a2e89fc10a29bc83fb685155fe14/pymilvus_model-0.3.2-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai==1.82.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.82.0) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai==1.82.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai==1.82.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai==1.82.0) (0.4.0)\n",
      "Collecting numpy>=1.26.0 (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/1d/0f/571b2c7a3833ae419fe69ff7b479a78d313581785203cc70a8db90121b9a/numpy-2.3.2-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (2025.2)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Collecting transformers>=4.36.0 (from pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/fa/0a/8791a6ee0529c45f669566969e99b75e2ab20eb0bfee8794ce295c18bdad/transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
      "Collecting onnxruntime (from pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/87/9d/45a995437879c18beff26eacc2322f4227224d04c6ac3254dce2e8950190/onnxruntime-1.22.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "Collecting scipy>=1.10.0 (from pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/e4/82/08e4076df538fb56caa1d489588d880ec7c52d8273a606bb54d660528f7c/scipy-1.16.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus==2.5.10->pymilvus[model]==2.5.10) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.0)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/39/7b/bb06b061991107cd8783f300adff3e7b7f284e330fd82f507f2a1417b11d/huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/ee/f6/4716198dbd0bcc9c45625ac4c81a435d1c4d8ad662e8576dac06bab35b17/regex-2025.7.34-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/f2/90/273b6c7ec78af547694eddeea9e05de771278bd20476525ab930cecaf7d8/tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/fe/5d/5a514d7b88e310c8b146e2404e0dc161282e78634d9358975fd56dfd14be/safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/b7/d6/13af5f916cef795ac2b5e4cc1de31f2e0e375f4475d50799915835f301c2/hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/miniconda3/lib/python3.13/site-packages (from jinja2->torch==2.7.0) (3.0.2)\n",
      "Collecting coloredlogs (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->pymilvus.model>=0.3.0->pymilvus[model]==2.5.10)\n",
      "  Using cached http://mirrors.tencentyun.com/pypi/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, flatbuffers, ujson, tzdata, triton, sympy, safetensors, requests, regex, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, milvus-lite, humanfriendly, hf-xet, grpcio, fsspec, filelock, scipy, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, coloredlogs, tokenizers, pymilvus, onnxruntime, nvidia-cusolver-cu12, transformers, torch, pymilvus.model\n",
      "\u001b[2K  Attempting uninstall: requests━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/42\u001b[0m [sympy]]\n",
      "\u001b[2K    Found existing installation: requests 2.32.4━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/42\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling requests-2.32.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/42\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.4━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/42\u001b[0m [requests]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/42\u001b[0m [pymilvus.model]us.model]ormers]er-cu12]2]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 filelock-3.19.1 flatbuffers-25.2.10 fsspec-2025.7.0 grpcio-1.67.1 hf-xet-1.1.8 huggingface-hub-0.34.4 humanfriendly-10.0 milvus-lite-2.5.1 mpmath-1.3.0 networkx-3.5 numpy-2.3.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 onnxruntime-1.22.1 pandas-2.3.2 protobuf-6.32.0 pymilvus-2.5.10 pymilvus.model-0.3.2 regex-2025.7.34 requests-2.32.3 safetensors-0.6.2 scipy-1.16.1 sympy-1.14.0 tokenizers-0.21.4 torch-2.7.0 transformers-4.55.4 triton-3.3.0 tzdata-2025.2 ujson-5.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"pymilvus[model]==2.5.10\" openai==1.82.0 requests==2.32.3 tqdm==4.67.1 torch==2.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c0999-d670-41a9-afbd-d8a020fe1631",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "375ad823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 从环境变量获取 DeepSeek API Key\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44bb26",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f92a95",
   "metadata": {},
   "source": [
    "我们使用 Milvus 文档 2.4.x 中的 FAQ 页面作为我们 RAG 中的私有知识库，这是一个简单 RAG 管道的良好数据源。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8b9e2",
   "metadata": {},
   "source": [
    "下载 zip 文件并将文档解压到 `milvus_docs` 文件夹。\n",
    "\n",
    "**建议在命令行执行下面命令**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81fa031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://github.com/milvus-io/milvus-docs/releases/download/v2.4.6-preview/milvus_docs_2.4.x_en.zip\n",
    "#!unzip -q milvus_docs_2.4.x_en.zip -d milvus_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1198466",
   "metadata": {},
   "source": [
    "我们从 `milvus_docs/en/faq` 文件夹加载所有 markdown 文件。对于每个文档，我们简单地使用 \"# \" 来分割文件中的内容，这样可以大致分离出 markdown 文件中每个主要部分的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9035a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "text_lines = []\n",
    "\n",
    "for file_path in glob(\"milvus_docs/en/faq/*.md\", recursive=True):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        file_text = file.read()\n",
    "\n",
    "    text_lines += file_text.split(\"# \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b73e74-ee7d-4daf-b7db-1c7a10bfc0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc2a0b8",
   "metadata": {},
   "source": [
    "### 准备 LLM 和 Embedding 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eaff7a",
   "metadata": {},
   "source": [
    "DeepSeek 支持 OpenAI 风格的 API，您可以使用相同的 API 进行微小调整来调用 LLM。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b994eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "deepseek_client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.deepseek.com/v1\",  # DeepSeek API 的基地址\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5a5e2",
   "metadata": {},
   "source": [
    "定义一个 embedding 模型，使用 `milvus_model` 来生成文本嵌入。我们以 `DefaultEmbeddingFunction` 模型为例，这是一个预训练的轻量级嵌入模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a94242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from pymilvus import model as milvus_model\n",
    "\n",
    "# embedding_model = milvus_model.DefaultEmbeddingFunction()\n",
    "\n",
    "from pymilvus import model as milvus_model\n",
    "\n",
    "# OpenAI国内代理 https://api.apiyi.com/token \n",
    "embedding_model = milvus_model.dense.OpenAIEmbeddingFunction(\n",
    "    model_name='text-embedding-3-large', # Specify the model name\n",
    "    api_key='sk-ZZdE4iSa4uUTRUolCe7719B2230847DcB0F577A687A074D7', # Provide your OpenAI API key\n",
    "    base_url='https://api.apiyi.com/v1',\n",
    "    dimensions=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb1696",
   "metadata": {},
   "source": [
    "生成一个测试嵌入并打印其维度和前几个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a27567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "[-0.02820087  0.00431641 -0.01861579  0.08197387 -0.03170586 -0.05268216\n",
      " -0.04881952  0.12474906 -0.02083324  0.03973515]\n"
     ]
    }
   ],
   "source": [
    "test_embedding = embedding_model.encode_queries([\"This is a test\"])[0]\n",
    "embedding_dim = len(test_embedding)\n",
    "print(embedding_dim)\n",
    "print(test_embedding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7683f3a-d9e4-4c8e-9a66-c341911bef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00578664  0.02242682 -0.01892621  0.12811586 -0.01249751 -0.07321841\n",
      " -0.00281971  0.08617394 -0.04377401  0.03073668]\n"
     ]
    }
   ],
   "source": [
    "test_embedding_0 = embedding_model.encode_queries([\"That is a test\"])[0]\n",
    "print(test_embedding_0[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a778887",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 将数据加载到 Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b23a24",
   "metadata": {},
   "source": [
    "### 创建 Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e84b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(uri=\"./milvus_demo.db\")\n",
    "\n",
    "collection_name = \"my_rag_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68648561",
   "metadata": {},
   "source": [
    "关于 `MilvusClient` 的参数：\n",
    "\n",
    "*   将 `uri` 设置为本地文件，例如 `./milvus.db`，是最方便的方法，因为它会自动利用 Milvus Lite 将所有数据存储在此文件中。\n",
    "*   如果您有大规模数据，可以在 Docker 或 Kubernetes 上设置性能更高的 Milvus 服务器。在此设置中，请使用服务器 URI，例如 `http://localhost:19530`，作为您的 `uri`。\n",
    "*   如果您想使用 Zilliz Cloud（Milvus 的完全托管云服务），请调整 `uri` 和 `token`，它们对应 Zilliz Cloud 中的 Public Endpoint 和 Api key。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce1bf3e",
   "metadata": {},
   "source": [
    "检查 collection 是否已存在，如果存在则删除它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aee85c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if milvus_client.has_collection(collection_name):\n",
    "    milvus_client.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb379f",
   "metadata": {},
   "source": [
    "创建一个具有指定参数的新 collection。\n",
    "\n",
    "如果我们不指定任何字段信息，Milvus 将自动创建一个默认的 `id` 字段作为主键，以及一个 `vector` 字段来存储向量数据。一个保留的 JSON 字段用于存储非 schema 定义的字段及其值。\n",
    "\n",
    "`metric_type` (距离度量类型):\n",
    "     作用：定义如何计算向量之间的相似程度。\n",
    "     例如：`IP` (内积) - 值越大通常越相似；`L2` (欧氏距离) - 值越小越相似；`COSINE` (余弦相似度) - 通常转换为距离，值越小越相似。\n",
    "     选择依据：根据你的嵌入模型的特性和期望的相似性定义来选择。\n",
    "\n",
    " `consistency_level` (一致性级别):\n",
    "     作用：定义数据写入后，读取操作能多快看到这些新数据。\n",
    "     例如：\n",
    "         `Strong` (强一致性): 总是读到最新数据，可能稍慢。\n",
    "         `Bounded` (有界过期): 可能读到几秒内旧数据，性能较好 (默认)。\n",
    "         `Session` (会话一致性): 自己写入的自己能立刻读到。\n",
    "         `Eventually` (最终一致性): 最终会读到新数据，但没时间保证，性能最好。\n",
    "     选择依据：在数据实时性要求和系统性能之间做权衡。\n",
    "\n",
    "简单来说：\n",
    " `metric_type`：怎么算相似。\n",
    " `consistency_level`：新数据多久能被读到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd0b2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=embedding_dim,\n",
    "    metric_type=\"IP\",  # 内积距离\n",
    "    consistency_level=\"Strong\",  # 支持的值为 (`\"Strong\"`, `\"Session\"`, `\"Bounded\"`, `\"Eventually\"`)。更多详情请参见 https://milvus.io/docs/consistency.md#Consistency-Level。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15bafb",
   "metadata": {},
   "source": [
    "### 插入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d3b35",
   "metadata": {},
   "source": [
    "遍历文本行，创建嵌入，然后将数据插入 Milvus。\n",
    "\n",
    "这里有一个新字段 `text`，它是在 collection schema 中未定义的字段。它将自动添加到保留的 JSON 动态字段中，该字段在高级别上可以被视为普通字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad077094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 72/72 [00:00<00:00, 923516.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'insert_count': 72, 'ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], 'cost': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "doc_embeddings = embedding_model.encode_documents(text_lines)\n",
    "\n",
    "for i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n",
    "    data.append({\"id\": i, \"vector\": doc_embeddings[i], \"text\": line})\n",
    "\n",
    "milvus_client.insert(collection_name=collection_name, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd971f6b",
   "metadata": {},
   "source": [
    "## 构建 RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dc076",
   "metadata": {},
   "source": [
    "### 检索查询数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fd7e7",
   "metadata": {},
   "source": [
    "我们指定一个关于 Milvus 的常见问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e2f5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How is data stored in milvus?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52401a38",
   "metadata": {},
   "source": [
    "在 collection 中搜索该问题，并检索语义上最匹配的前3个结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd4cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_res = milvus_client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=embedding_model.encode_queries(\n",
    "        [question]\n",
    "    ),  # 将问题转换为嵌入向量\n",
    "    limit=3,  # 返回前3个结果\n",
    "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # 内积距离\n",
    "    output_fields=[\"text\"],  # 返回 text 字段\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcce135",
   "metadata": {},
   "source": [
    "让我们看一下查询的搜索结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7f6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    [\n",
      "        \" Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\",\n",
      "        0.7751178741455078\n",
      "    ],\n",
      "    [\n",
      "        \"How does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n###\",\n",
      "        0.643004298210144\n",
      "    ],\n",
      "    [\n",
      "        \"How does Milvus flush data?\\n\\nMilvus returns success when inserted data are loaded to the message queue. However, the data are not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.\\n\\n###\",\n",
      "        0.6181490421295166\n",
      "    ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "retrieved_lines_with_distances = [\n",
    "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
    "]\n",
    "print(json.dumps(retrieved_lines_with_distances, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4c186",
   "metadata": {},
   "source": [
    "### 使用 LLM 获取 RAG 响应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1ae3a",
   "metadata": {},
   "source": [
    "将检索到的文档转换为字符串格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0676448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join(\n",
    "    [line_with_distance[0] for line_with_distance in retrieved_lines_with_distances]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "107df42a-b3f7-48a8-b66b-fc82fe3ec174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\\nHow does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n###\\nHow does Milvus flush data?\\n\\nMilvus returns success when inserted data are loaded to the message queue. However, the data are not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.\\n\\n###\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19998758-7f98-4cb8-8789-625fcfaad00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How is data stored in milvus?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad25756",
   "metadata": {},
   "source": [
    "为语言模型定义系统和用户提示。此提示是使用从 Milvus 检索到的文档组装而成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b655f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Human: 你是一个 AI 助手。你能够从提供的上下文段落片段中找到问题的答案。\n",
    "\"\"\"\n",
    "USER_PROMPT = f\"\"\"\n",
    "请使用以下用 <context> 标签括起来的信息片段来回答用 <question> 标签括起来的问题。最后追加原始回答的中文翻译，并用 <translated>和</translated> 标签标注。\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "<translated>\n",
    "</translated>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97089c31-f85c-47a9-8498-78520513bc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n请使用以下用 <context> 标签括起来的信息片段来回答用 <question> 标签括起来的问题。最后追加原始回答的中文翻译，并用 <translated>和</translated> 标签标注。\\n<context>\\n Where does Milvus store data?\\n\\nMilvus deals with two types of data, inserted data and metadata. \\n\\nInserted data, including vector data, scalar data, and collection-specific schema, are stored in persistent storage as incremental log. Milvus supports multiple object storage backends, including [MinIO](https://min.io/), [AWS S3](https://aws.amazon.com/s3/?nc1=h_ls), [Google Cloud Storage](https://cloud.google.com/storage?hl=en#object-storage-for-companies-of-all-sizes) (GCS), [Azure Blob Storage](https://azure.microsoft.com/en-us/products/storage/blobs), [Alibaba Cloud OSS](https://www.alibabacloud.com/product/object-storage-service), and [Tencent Cloud Object Storage](https://www.tencentcloud.com/products/cos) (COS).\\n\\nMetadata are generated within Milvus. Each Milvus module has its own metadata that are stored in etcd.\\n\\n###\\nHow does Milvus handle vector data types and precision?\\n\\nMilvus supports Binary, Float32, Float16, and BFloat16 vector types.\\n\\n- Binary vectors: Store binary data as sequences of 0s and 1s, used in image processing and information retrieval.\\n- Float32 vectors: Default storage with a precision of about 7 decimal digits. Even Float64 values are stored with Float32 precision, leading to potential precision loss upon retrieval.\\n- Float16 and BFloat16 vectors: Offer reduced precision and memory usage. Float16 is suitable for applications with limited bandwidth and storage, while BFloat16 balances range and efficiency, commonly used in deep learning to reduce computational requirements without significantly impacting accuracy.\\n\\n###\\nHow does Milvus flush data?\\n\\nMilvus returns success when inserted data are loaded to the message queue. However, the data are not yet flushed to the disk. Then Milvus' data node writes the data in the message queue to persistent storage as incremental logs. If `flush()` is called, the data node is forced to write all data in the message queue to persistent storage immediately.\\n\\n###\\n</context>\\n<question>\\nHow is data stored in milvus?\\n</question>\\n<translated>\\n</translated>\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USER_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b457f",
   "metadata": {},
   "source": [
    "使用 DeepSeek 提供的 `deepseek-chat` 模型根据提示生成响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "638a7561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milvus stores data in two forms: inserted data and metadata. Inserted data (including vector data, scalar data, and collection schema) are stored as incremental logs in persistent object storage backends such as MinIO, AWS S3, Google Cloud Storage, Azure Blob Storage, Alibaba Cloud OSS, or Tencent Cloud COS. Metadata, generated internally by Milvus modules, are stored in etcd.\n",
      "\n",
      "<translated>\n",
      "Milvus以两种形式存储数据：插入的数据和元数据。插入的数据（包括向量数据、标量数据和集合模式）以增量日志的形式存储在持久化对象存储后端，如MinIO、AWS S3、Google Cloud Storage、Azure Blob Storage、阿里云OSS或腾讯云COS。元数据由Milvus模块内部生成，存储在etcd中。\n",
      "</translated>\n"
     ]
    }
   ],
   "source": [
    "response = deepseek_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62909e48-48da-4aef-b5d2-86fbfbf3d5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
